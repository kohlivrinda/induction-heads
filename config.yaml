---
num_layers: 2
num_heads: 8
emb_dim: 64
hidden_dim: 256
max_seq_len: 256
vocab_size: 50257
dropout_ratio: 0.1
batch_size: 32
learning_rate: 5e-4
epochs: 10
mask_input: True
qk_attn: True
max_grad_norm: 1.0