---
model:
  n_layers: 2
  n_heads: 8
  d_model: 256
  d_ff: 1024
  max_seq_len: 512
  vocab_size: 10000
  dropout: 0.1
  batch_size: 64
  learning_rate: 5e-4
  epochs: 10 
---
